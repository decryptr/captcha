[{"path":"https://decryptr.github.io/captcha/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 decryptr Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://decryptr.github.io/captcha/articles/advanced.html","id":"model-r-details","dir":"Articles","previous_headings":"","what":"03_model.R details","title":"Advanced Usage","text":"first step script creates objects type dataset (object stores data consistently) dataloader (object obtains samples dataset, used minibatches inside model), using framework orchestrated torch package. captcha_dataset() function creates dataset, taking folder parameter generates object classes my_captcha, dataset R6. function actually dataset_generator object, created using dataset() function torch package. object called way usual R function, accepting additional parameters: transform_image=: transformation function applied image. default, uses captcha_transform_image() function, reads image resizes 32x192 dimensions. dimension chosen facilitate implementation convolutional layers deal fact usually Captchas rectangular images. transform_label=: transformation function generate response variable. default, uses captcha_transform_label() function, receives vector possible Captcha elements applies one_hot() operation, obtaining matrix version response zeros ones. augmentation=: operations data augmentation. example, function adds random noise original image one resample , obtained data always different. captcha_dataset() function must used twice, create training dataset create validation dataset. separation training validation datasets must done manually, copying part classified Captchas new folder, using randomization. Next, dataloaders created using dataloader() function torch package. part, size minibatch defined, addition possible parameters. details, access function documentation link. dataloaders must created training validation datasets. next step involves model specification. modeling script, model provided net_captcha object captcha package. case dataset, net_captcha special object torch, classes CAPTCHA-CNN, nn_module nn_module_generator. object can used function, generating torch module, similar prediction function. However, due way object used later steps luz package, object considered nn_module_generator, stated script. customize model, user must create new module, modifying initialize() forward() methods, can accessed inside net_captcha$public_methods object. first responsible initializing model, containing description operations performed, convolutions. second feed forward function neural networks, receives image returns object containing logits probabilities, format response variable. default, template code described . parameters input_dim=, output_ndigits=, output_vocab_size= vocab= describe, respectively, dimensions image, length response, length alphabet elements alphabet. transform=, dropout= dense_units= parameters control, respectively, image transformation function, dropout hyperparameters number units dense layer. Notice parameters convolutions fixed, already prepared work well image dimensions 32x192. feed forward function described . function applies step--step procedure convolutional neural network, image x input returning logit matrix giving model weights letter answer. model returns logits, probabilities, loss function takes logits input. user decides modify forward method return probabilities, also need adapt used loss function. architecture model defined, penultimate step fitting step. orchestrated luz package, facilitates creation optimization loop. luz package plays role similar keras tensorflow. case Captchas, luz code fit model organized four steps, linked pipe operator, |>: setup(): determines loss function, optimizer metrics monitored. loss function used script nn_multilabel_soft_margin_loss() torch, optimizer optim_adam() torch metric captcha_accuracy(), developed captcha package show accuracy considering complete Captcha image accuracy letter image, result luz_metric_accuracy() function luz package. set_hparams(): informs hyperparameters model information. parameters function initialize() method neural network created previous step. set_opt_hparams(): informs optimization hyperparameters. Parameters placed function passed optimization function. script, used parameter learning rate, fixed 0.01. learning rate decay parameter using multiplicative rate. iteration, learning rate decays factor determined function defined lr_lambda, default 0.99. , epoch, learning rate 1% lower. early stopping. default, set stop 20 epochs model improve accuracy 1% validation dataset. log file. default, model saves fitting history comma separated values (CSV) file, containing loss accuracy model training validation datasets, end epoch. log file important monitor model fitting check performance epochs. workflow defined luz package returns fitted model object. model luz_module_fitted class can inspected running object R console. example shown . object contains concise informative report, showing total time, metrics obtained training validation, architecture fitted model. Lastly, model must saved local file. accomplished using luz_save() function luz package, saving object .pt extension, used 04_share.R.","code":"initialize = function(input_dim,                       output_ndigits,                       output_vocab_size,                       vocab,                       transform,                       dropout = c(.25, .25),                       dense_units = 400) {      # in_channels, out_channels, kernel_size, stride = 1, padding = 0   self$batchnorm0 <- torch::nn_batch_norm2d(3)   self$conv1 <- torch::nn_conv2d(3, 32, 3)   self$batchnorm1 <- torch::nn_batch_norm2d(32)   self$conv2 <- torch::nn_conv2d(32, 64, 3)   self$batchnorm2 <- torch::nn_batch_norm2d(64)   self$conv3 <- torch::nn_conv2d(64, 64, 3)   self$batchnorm3 <- torch::nn_batch_norm2d(64)   self$dropout1 <- torch::nn_dropout2d(dropout[1])   self$dropout2 <- torch::nn_dropout2d(dropout[2])      self$fc1 <- torch::nn_linear(     # must be the same as last convnet     in_features = prod(calc_dim_conv(input_dim)) * 64,     out_features = dense_units   )   self$batchnorm_dense <- torch::nn_batch_norm1d(dense_units)   self$fc2 <- torch::nn_linear(     in_features = dense_units,     out_features = output_vocab_size * output_ndigits   )   self$output_vocab_size <- output_vocab_size   self$input_dim <- input_dim   self$output_ndigits <- output_ndigits   self$vocab <- vocab   self$transform <- transform } forward = function(x) {    out <- x |>     # normalize     self$batchnorm0() |>     # layer 1     self$conv1() |>     torch::nnf_relu() |>     torch::nnf_max_pool2d(2) |>     self$batchnorm1() |>          # layer 2     self$conv2() |>     torch::nnf_relu() |>     torch::nnf_max_pool2d(2) |>     self$batchnorm2() |>          # layer 3     self$conv3() |>     torch::nnf_relu() |>     torch::nnf_max_pool2d(2) |>     self$batchnorm3() |>          # dense     torch::torch_flatten(start_dim = 2) |>     self$dropout1() |>     self$fc1() |>     torch::nnf_relu() |>     self$batchnorm_dense() |>     self$dropout2() |>     self$fc2()      out$view(c(     dim(out)[1],     self$output_ndigits,     self$output_vocab_size   ))    } A `luz_module_fitted` ── Time ──────────────────────────────────────────────── • Total time: 10m 48.1s • Avg time per training batch: 415ms • Avg time per validation batch 217ms  ── Results ───────────────────────────────────────────── Metrics observed in the last epoch.  ℹ Training: loss: 0.0049 captcha acc: 0.996 ℹ Validation: loss: 0.0356 captcha acc: 0.905  ── Model ─────────────────────────────────────────────── An `nn_module` containing 628,486 parameters.  ── Modules ───────────────────────────────────────────── • batchnorm0: <nn_batch_norm2d> #6 parameters • conv1: <nn_conv2d> #896 parameters • batchnorm1: <nn_batch_norm2d> #64 parameters • conv2: <nn_conv2d> #18,496 parameters • batchnorm2: <nn_batch_norm2d> #128 parameters • conv3: <nn_conv2d> #36,928 parameters • batchnorm3: <nn_batch_norm2d> #128 parameters • dropout1: <nn_dropout> #0 parameters • dropout2: <nn_dropout> #0 parameters • fc1: <nn_linear> #563,400 parameters • batchnorm_dense: <nn_batch_norm1d> #400 parameters • fc2: <nn_linear> #8,040 parameters"},{"path":"https://decryptr.github.io/captcha/articles/advanced.html","id":"share-r-details","dir":"Articles","previous_headings":"","what":"04_share.R details","title":"Advanced Usage","text":"script uses usethis package organize repository, configuring Git (code versioning software) GitHub (web repository organization system). Furthermore, script uses piggyback package make fitted model available releases new repository. Optionally, user can also make raw data annotated files available .zip file, recommended, allows people work data improve models. Um detalhe importante é sobre inserção de arquivos pesados repositório. O script utiliza releases para disponibilizar soluções porque não é uma boa prática subir arquivos como modelos ajustados ou arquivos brutos (imagens) diretamente repositório. Isso acontece porque o repositório pode ficar demasiadamente pesado e o histórico Git fica alterado. important detail usage heavy files git repository. script uses releases share solutions good practice upload files fitted models raw files (images) directly repository. happens repository can become heavy git algorithm handle. shared across releases repository, model readable anyone using captcha package. Just run code model loaded. , work can shared Captchas can solved collaborative manner community. Using new_captcha() workflow, user flexibility build custom models ease share results.","code":"model <- captcha_load_model(\"<name>\", \"<user>/<repo>\")"},{"path":"https://decryptr.github.io/captcha/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Julio Trecenti. Maintainer, author.","code":""},{"path":"https://decryptr.github.io/captcha/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Trecenti J (2022). captcha: Solve Captchas Using Torch. https://github.com/decryptr/captcha, https://decryptr.github.io/captcha/.","code":"@Manual{,   title = {captcha: Solve Captchas Using Torch},   author = {Julio Trecenti},   year = {2022},   note = {https://github.com/decryptr/captcha, https://decryptr.github.io/captcha/}, }"},{"path":"https://decryptr.github.io/captcha/index.html","id":"captcha-","dir":"","previous_headings":"","what":"Solve Captchas Using Torch","title":"Solve Captchas Using Torch","text":"package extensible API build models solve Captchas (Completely Automated Public Turing test tell Computers Humans Apart). provides tools read Captchas, visualize Captchas, annotate Captchas, fit models, share fitted models.","code":""},{"path":"https://decryptr.github.io/captcha/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Solve Captchas Using Torch","text":"One can install development version captcha package running","code":"remotes::install_github(\"decryptr/captcha\")"},{"path":"https://decryptr.github.io/captcha/index.html","id":"basic-usage","dir":"","previous_headings":"","what":"Basic usage","title":"Solve Captchas Using Torch","text":"basic usage captcha involves functions read_captcha(), plot(), captcha_annotate(), captcha_load_model() decrypt(). diagram summarizes relationships functions. arrows indicate dependency functions objects generated functions.","code":""},{"path":"https://decryptr.github.io/captcha/index.html","id":"read-and-visualize","dir":"","previous_headings":"Basic usage","what":"Read and visualize","title":"Solve Captchas Using Torch","text":"read_captcha() function reads character vector image files stores memory. Behind scenes, function uses {magick} package deal types files may appear (JPEG, PNG, among others).  function returns object class captcha, can used methods. captcha object list three elements: $img, contains image read magick package; $lab, contains image label (default, NULL); $path, contains path image. read_captcha() function lab_in_path= parameter, indicates whether image path contains label. lab_in_path=TRUE, function try extract label file (getting text comes last _ path) store $lab element. plot() function method class S3 base R. function facilitates visualization Captchas. function receives list images (obtained read_captcha() function) displays Captcha visually.  interesting aspect plot() function deals list Captchas. useful goal view several Captchas image simultaneously. next image shows example.  default, plot() function arranges images four columns. change default, one can modify options using options(captcha.print.cols = N), N desired number columns. next image shows example two columns.  list Captchas long, plot() function displays maximum number images accompanied message. default, number 100, 25 rows four columns. One can override option combining captcha.print.cols= captcha.print.rows= options. next image shows example function’s behavior number images exceeds 100.  possible create subsets captcha objects using [ operator. One can also use length() function measure number images. next image shows example operations.  Finally, image label, plot() function shows label corner image. following image shows example.","code":"library(captcha) example <- \"man/figures/dados_tjmg.jpeg\" captcha <- read_captcha(example)  captcha #>   format width height colorspace matte filesize density #> 1   JPEG   100     50       sRGB FALSE     4530   72x72 class(captcha) #> [1] \"captcha\" str(captcha) #> Class 'captcha'  hidden list of 3 #>  $ img :Class 'magick-image' <externalptr>  #>  $ lab : NULL #>  $ path: chr \"man/figures/dados_tjmg.jpeg\" example <- \"man/figures/mnist128c49c36e13_6297.png\" captcha <- read_captcha(example, lab_in_path = TRUE)  str(captcha) #> Class 'captcha'  hidden list of 3 #>  $ img :Class 'magick-image' <externalptr>  #>  $ lab : chr \"6297\" #>  $ path: chr \"man/figures/mnist128c49c36e13_6297.png\" example <- \"man/figures/dados_tjmg.jpeg\" captcha <- read_captcha(example) plot(captcha) examples <- paste0(\"man/figures/\", c(   \"dados_tjmg.jpeg\",   \"dados_esaj.png\",   \"dados_rfb.png\",   \"dados_sei.png\" )) captchas <- read_captcha(examples) plot(captchas) options(captcha.print.cols = 2) plot(captchas) # more than 100 imagens: examples <- rep(\"man/figures/dados_tjmg.jpeg\", 110) captchas <- read_captcha(examples) plot(captchas) #> ℹ Too many images, printing first 100. To override, run #> • options('captcha.print.rows' = MAX_ROWS) #> • options('captcha.print.cols' = COLUMNS) captchas_subset <- captchas[1:20] length(captchas_subset) # 20 #> [1] 20 plot(captchas_subset) example <- \"man/figures/mnist128c49c36e13_6297.png\" captcha <- read_captcha(example, lab_in_path = TRUE) plot(captcha)"},{"path":"https://decryptr.github.io/captcha/index.html","id":"annotate","dir":"","previous_headings":"Basic usage","what":"Annotate","title":"Solve Captchas Using Torch","text":"captcha_annotate() function annotates Captcha image, either manually automatically. modifies image path adds text _label end file path. function following parameters: files=: object class captcha read function read_captcha() (recommended) character vector file paths. labels=: (optional) character vector image labels. must length() files=. value NULL default, prompting user enter label manually. path=: (optional) path folder save annotated files. default, saves files modified names folder original files. rm_old=: (optional) whether delete original files. Defaults FALSE. captcha_annotate() function returns vector paths modified files. labels= parameter can handle situations one knows Captcha label. example, workflow uses oracle might provide label automatically. label doesn’t exist, captcha_annotate() function opens prompt classification shows image using plot(). following image shows application example captcha_annotate() function RStudio.","code":""},{"path":"https://decryptr.github.io/captcha/index.html","id":"predict","dir":"","previous_headings":"Basic usage","what":"Predict","title":"Solve Captchas Using Torch","text":"decrypt() function returns label image using fitted model. function takes two arguments: file=, can either file path captcha class object, model=, contains object class luz_module_fitted, fitted using {luz} package.  fitted models several different Captchas available captcha package. possible load trained model using captcha_load_model() function. path= parameter contains either path fitted model string name released model, like \"rfb\". Fitted models stored captcha package repository releases, can downloaded using {piggyback} package package. Currently, Captchas available fitted models trf5, tjmg, trt, esaj, jucesp, tjpe, tjrs, cadesp, sei rfb. table describes models accuracy.","code":"model <- captcha_load_model(\"cadesp\") img <- \"man/figures/dados_cadesp.jpg\" captcha <- read_captcha(img) plot(captcha) decrypt(captcha, model) #> [1] \"dwyy\""},{"path":"https://decryptr.github.io/captcha/index.html","id":"fit-custom-model","dir":"","previous_headings":"Basic usage","what":"Fit custom model","title":"Solve Captchas Using Torch","text":"captcha package provides basic interface fitting custom models fully labeled data. Annotation can done manually using captcha_annotate() function presented earlier another method developed user. model uses convolutional neural network architecture, similar LeNet-5 model. modeling step assumptions file names. Images must folder pattern path//file/<id>_<lab>.<ext>, : <id>: can name, preferably without accents special characters, avoid encoding issues. usually contains name type hash identify image uniquely. Note: annotating file, id must unique, two Captchas can label. <lab>: Captcha label. string characters [-zA-Z0-9], can case-sensitive necessary. labels must length. <ext>: file extension. can .png, .jpeg .jpg. operations also work .svg format, may problems due image’s transparency. captcha_fit_model() function fits model folder annotated images. function considers parameters: dir=: path annotated files; dir_valid=: (optional) path annotated files validation; prop_valid=:, proportion training set considered validation. prop_valid= ignored dir_valid= given (default, 20% dataset considered validation). captcha_fit_model() function also parameters related neural network. : dropout=: dropout percentage applied hidden layers network (default, 0.25); dense_units=: number units hidden layer comes convolutional layers (default, 200); decay=: learning rate decay percentage (default, 0.99); epochs=: number epochs fit model (default, 100). important note model stops fitting 20 iterations without significant increment accuracy (chosen 1%; details, see advanced guide). function returns fitted model class luz_module_fitted, can saved disk using luz_save(). One can also serialize model use packages PyTorch. tutorial serialization can found torch package documentation. Fitting new Captcha model can challenging. help , captcha package documentation provides application example. example uses Captchas captcha_generate() function, generates Captchas using magick package. captcha_generate() function following parameters: write_disk=: save files disk? default, FALSE. path=: Path save files disk, previous parameter TRUE. chars=: characters use image. n_chars=: length Captcha. n_rows=: Height image, pixels. n_cols=: Width image, pixels. p_rotate=: Probability image rotation. p_line=: Probability adding line letters. p_stroke=: Probability adding border letters. p_box=: Probability adding box (rectangle) around letters. p_implode=: Probability adding implode effects. p_oilpaint=: Probability add oil paint effects. p_noise=: Probability adding white noise background image. p_lat=: Probability applying local adaptive thresholding algorithm image.","code":""},{"path":"https://decryptr.github.io/captcha/index.html","id":"advanced-usage","dir":"","previous_headings":"","what":"Advanced usage","title":"Solve Captchas Using Torch","text":"premises classified base met, possible fit neural network model using captcha package. However, training step involves many small adaptations, decided export functions two depth levels. address , captcha package also provides procedural approach fit model, using step--step described advanced guide.","code":""},{"path":"https://decryptr.github.io/captcha/reference/available_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Available models for prediction — available_models","title":"Available models for prediction — available_models","text":"Available models prediction using decrypt().","code":""},{"path":"https://decryptr.github.io/captcha/reference/available_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Available models for prediction — available_models","text":"","code":"available_models()"},{"path":"https://decryptr.github.io/captcha/reference/available_models.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Available models for prediction — available_models","text":"Currently, available captchas : trf5: Tribunal Regional Federal 5 tjmg: Tribunal de Justiça de Minas Gerais trt: Tribunal Regional Trabalho 3 esaj: Tribunal de Justiça da Bahia jucesp: Junta Comercial de São Paulo tjpe: Tribunal de Justiça de Pernambuco tjrs: Tribunal de Justiça Rio Grande Sul cadesp: Centro de Apoio ao Desenvolvimento da Saúde Pública sei: Sistema Eletrônico de Informações - rfb: Receita Federal","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Captcha accuracy metric — captcha_accuracy","title":"Captcha accuracy metric — captcha_accuracy","text":"Captcha accuracy metric","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Captcha accuracy metric — captcha_accuracy","text":"","code":"captcha_accuracy()"},{"path":"https://decryptr.github.io/captcha/reference/captcha_annotate.html","id":null,"dir":"Reference","previous_headings":"","what":"Annotate captchas with their labels — captcha_annotate","title":"Annotate captchas with their labels — captcha_annotate","text":"Given one Captchas, function prompts solve mannually later can train model labels. Annotated captchas saved path labels filename separated underscore.","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_annotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annotate captchas with their labels — captcha_annotate","text":"","code":"captcha_annotate(files, labels = NULL, path = NULL, rm_old = FALSE)"},{"path":"https://decryptr.github.io/captcha/reference/captcha_annotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Annotate captchas with their labels — captcha_annotate","text":"files Either object class captcha character vector paths captcha files labels Either NULL (interactive classification) character vector labels Captchas path save annotated captcha files. NULL, saves files folder unanswered counterparts. rm_old Whether delete unanswered captchas copying renaming ","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_annotate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Annotate captchas with their labels — captcha_annotate","text":"character vector paths newly created files","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Captcha datasets — captcha_dataset","title":"Captcha datasets — captcha_dataset","text":"Captcha datasets","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Captcha datasets — captcha_dataset","text":"","code":"captcha_dataset(   root,   transform_image = captcha::captcha_transform_image,   transform_label = captcha::captcha_transform_label,   augmentation = NULL )"},{"path":"https://decryptr.github.io/captcha/reference/captcha_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Captcha datasets — captcha_dataset","text":"root (string): root directory files stored transform_image (callable, optional): function/transform takes file path returns torch tensor prepared feed model. transform_label (callable, optional): function/transform takes file paths transform . augmentation (function, optional) NULL, applies function augment data randomized preprocessing layers.","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_fit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Captcha model — captcha_fit_model","title":"Fit Captcha model — captcha_fit_model","text":"Fit Captcha model","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_fit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Captcha model — captcha_fit_model","text":"","code":"captcha_fit_model(   dir,   dir_valid = NULL,   prop_valid = 0.2,   dropout = 0.25,   dense_units = 200,   decay = 0.99,   batch_size = 40,   epochs = 100 )"},{"path":"https://decryptr.github.io/captcha/reference/captcha_fit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Captcha model — captcha_fit_model","text":"dir directory classified images dir_valid (optional) directory validation files prop_valid proportion total images considered validation. Default 0.2. dropout dropout hyperparameter. Default 0.25. dense_units number dense units use convolution steps. Default 200. decay Weight decay applied epoch. batch_size Minibatch size. Default 40. epochs Number epochs use. Default 100. model uses early stopping, possible procedure ends total number epochs actually run.","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_fit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Captcha model — captcha_fit_model","text":"fitted model class luz_module_fitted","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate captcha — captcha_generate","title":"Generate captcha — captcha_generate","text":"Generates random captcha image","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate captcha — captcha_generate","text":"","code":"captcha_generate(   write_disk = FALSE,   path = getwd(),   chars = c(0:9, letters, LETTERS),   n_chars = 4,   n_rows = 60,   n_cols = 120,   p_rotate = 0.8,   p_line = 0.8,   p_stroke = 0.3,   p_box = 0.3,   p_implode = 0.2,   p_oilpaint = 0,   p_noise = 0.4,   p_lat = 0 )"},{"path":"https://decryptr.github.io/captcha/reference/captcha_generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate captcha — captcha_generate","text":"write_disk write image disk? Defaults FALSE. path path save images. Defaults current directory. chars chars generate. Defaults upper/lower case letters numbers n_chars captcha length. Defaults 4. n_rows, n_cols image dimensions. Defaults 60x120 image. p_rotate probability add rotation. Defaults 80%. p_line probability add strikethrough line. Defaults 80%. p_stroke probability add stroke color. Defaults 30%. p_box probability add bounding box text. Defaults 30%. p_implode probability add imploding effect. Defaults 20%. p_oilpaint probability add oilpaint effect. Defaults 0. p_noise probability add random noise image. Defaults 40%. p_lat probability add LAT algorithm image. Defaults 0.","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate captcha — captcha_generate","text":"list containing two elements: imagemagick object captcha value.","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate captcha — captcha_generate","text":"","code":"captcha_generate() #> # A tibble: 1 × 7 #>   format width height colorspace matte filesize density #>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>   #> 1 PNG      120     60 sRGB       FALSE        0 72x72   captcha_generate(n_chars = 5) #> # A tibble: 1 × 7 #>   format width height colorspace matte filesize density #>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>   #> 1 PNG      120     60 sRGB       FALSE        0 72x72"},{"path":"https://decryptr.github.io/captcha/reference/captcha_load_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Load captcha model — captcha_load_model","title":"Load captcha model — captcha_load_model","text":"Load captcha model","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_load_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load captcha model — captcha_load_model","text":"","code":"captcha_load_model(captcha, repo = \"decryptr/captcha\", tag = \"captcha_model\")"},{"path":"https://decryptr.github.io/captcha/reference/captcha_load_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load captcha model — captcha_load_model","text":"captcha file name captcha name repo repo form \"<user>/<captcha>\". Default \"decryptr/captcha\" tag tag name release load file.","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_transform_image.html","id":null,"dir":"Reference","previous_headings":"","what":"File to torch tensor — captcha_transform_image","title":"File to torch tensor — captcha_transform_image","text":"File torch tensor","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_transform_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"File to torch tensor — captcha_transform_image","text":"","code":"captcha_transform_image(x, input_dim = c(32L, 192L))"},{"path":"https://decryptr.github.io/captcha/reference/captcha_transform_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"File to torch tensor — captcha_transform_image","text":"x file path input_dim resize image dimension","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_transform_label.html","id":null,"dir":"Reference","previous_headings":"","what":"File to response matrix (tensor) — captcha_transform_label","title":"File to response matrix (tensor) — captcha_transform_label","text":"File response matrix (tensor)","code":""},{"path":"https://decryptr.github.io/captcha/reference/captcha_transform_label.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"File to response matrix (tensor) — captcha_transform_label","text":"","code":"captcha_transform_label(all_letters, vocab)"},{"path":"https://decryptr.github.io/captcha/reference/captcha_transform_label.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"File to response matrix (tensor) — captcha_transform_label","text":"all_letters list tokens files vocab unique tokens","code":""},{"path":"https://decryptr.github.io/captcha/reference/decrypt.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to solve Captchas — decrypt","title":"Function to solve Captchas — decrypt","text":"Function solve Captchas","code":""},{"path":"https://decryptr.github.io/captcha/reference/decrypt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to solve Captchas — decrypt","text":"","code":"decrypt(files, model)"},{"path":"https://decryptr.github.io/captcha/reference/decrypt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to solve Captchas — decrypt","text":"files files read. Can character vector object class captcha. model model class luz_module_fitted","code":""},{"path":"https://decryptr.github.io/captcha/reference/net_captcha.html","id":null,"dir":"Reference","previous_headings":"","what":"Net captcha — net_captcha","title":"Net captcha — net_captcha","text":"Net captcha","code":""},{"path":"https://decryptr.github.io/captcha/reference/net_captcha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Net captcha — net_captcha","text":"","code":"net_captcha(   input_dim,   output_ndigits,   output_vocab_size,   vocab,   transform,   dropout = c(0.25, 0.25),   dense_units = 400 )"},{"path":"https://decryptr.github.io/captcha/reference/net_captcha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Net captcha — net_captcha","text":"input_dim (integer, integer): image input dimensions. output_ndigits number tokens Captcha. output_vocab_size number unique token values. vocab token labels transform input transform function (prediction purposes) dropout (float, float) AlexNet dropout values. dense_units Number dense units","code":""},{"path":"https://decryptr.github.io/captcha/reference/new_captcha.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new project to solve a custom captcha — new_captcha","title":"Create a new project to solve a custom captcha — new_captcha","text":"Create new project solve custom captcha","code":""},{"path":"https://decryptr.github.io/captcha/reference/new_captcha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new project to solve a custom captcha — new_captcha","text":"","code":"new_captcha(path)"},{"path":"https://decryptr.github.io/captcha/reference/new_captcha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new project to solve a custom captcha — new_captcha","text":"path path. exists, used. exist, created, provided parent path exists.","code":""},{"path":"https://decryptr.github.io/captcha/reference/plot.captcha.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a captcha — plot.captcha","title":"Plot a captcha — plot.captcha","text":"Plot captcha","code":""},{"path":"https://decryptr.github.io/captcha/reference/plot.captcha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a captcha — plot.captcha","text":"","code":"# S3 method for captcha plot(x, y, ...)"},{"path":"https://decryptr.github.io/captcha/reference/plot.captcha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a captcha — plot.captcha","text":"x Captcha object read read_captcha() y used ... arguments passed graphics::plot()","code":""},{"path":"https://decryptr.github.io/captcha/reference/print.captcha.html","id":null,"dir":"Reference","previous_headings":"","what":"Print information about a captcha — print.captcha","title":"Print information about a captcha — print.captcha","text":"Print information captcha","code":""},{"path":"https://decryptr.github.io/captcha/reference/print.captcha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print information about a captcha — print.captcha","text":"","code":"# S3 method for captcha print(x, ...)"},{"path":"https://decryptr.github.io/captcha/reference/print.captcha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print information about a captcha — print.captcha","text":"x Captcha object read read_captcha() ...","code":""},{"path":"https://decryptr.github.io/captcha/reference/read_captcha.html","id":null,"dir":"Reference","previous_headings":"","what":"Read captcha files — read_captcha","title":"Read captcha files — read_captcha","text":"Given paths one files, reads converts captcha list can used modeling prediction. lab_in_path = TRUE, take label Captchas filenames get ready modeling.","code":""},{"path":"https://decryptr.github.io/captcha/reference/read_captcha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read captcha files — read_captcha","text":"","code":"read_captcha(files, lab_in_path = FALSE)"},{"path":"https://decryptr.github.io/captcha/reference/read_captcha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read captcha files — read_captcha","text":"files Paths one captcha images lab_in_path Whether labels captchas already paths files (separated underscore filename)","code":""},{"path":"https://decryptr.github.io/captcha/reference/read_captcha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read captcha files — read_captcha","text":"list captcha objects","code":""}]
