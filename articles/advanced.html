<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="captcha">
<title>Advanced Usage • captcha</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Advanced Usage">
<meta property="og:description" content="captcha">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">captcha</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/advanced.html">Advanced Usage</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/decryptr/captcha/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Advanced Usage</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/decryptr/captcha/blob/HEAD/vignettes/advanced.Rmd" class="external-link"><code>vignettes/advanced.Rmd</code></a></small>
      <div class="d-none name"><code>advanced.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/decryptr/captcha" class="external-link">captcha</a></span><span class="op">)</span></span></code></pre></div>
<p>Deep learning models often need several small adjustments, such as
the learning rate, use of other optimization functions, computational
layers and preprocessing functions. Because of that, in some situations,
it may be desirable to run custom models.</p>
<p>The <code><a href="../reference/captcha_fit_model.html">captcha_fit_model()</a></code> function is a good way to start,
but it is too rigid. It accepts some parameters to structure the model,
but it does not support customization. Packages like
<a href="https://torch.mlverse.org/docs" class="external-link">torch</a> and <a href="https://mlverse.github.io/luz/" class="external-link">luz</a> exist to help with this
issue, creating more flexible computing environments to operate deep
learning models.</p>
<p>Another disadvantage of using <code><a href="../reference/captcha_fit_model.html">captcha_fit_model()</a></code> is the
availability of the fitted models. A model can be used locally, but
sharing the data and the model to other people does not have a
well-defined procedure.</p>
<p>To organize the workflow, there is a workflow template implemented
inside the <a href="https://github.com/decryptr/captcha" class="external-link">captcha</a> package. The function that
orchestrates this workflow is <code><a href="../reference/new_captcha.html">new_captcha()</a></code>. The function
has only one parameter, <code>path=</code>, which is the path of the new
project.</p>
<p>It is also possible to call the function by creating a project within
RStudio. The following image shows an example of the template inside
RStudio, after clicking on
<code>New Project &gt; New Directory</code>.</p>
<div class="figure" style="text-align: center">
<img src="exemplo-rstudio-template.png" alt="Creating a new Captcha project using RStudio." width="70%"><p class="caption">
Creating a new Captcha project using RStudio.
</p>
</div>
<p>After creating a new project, via the <code><a href="../reference/new_captcha.html">new_captcha()</a></code>
command or via the RStudio interface, a new window opens. The project
contains four files:</p>
<ul>
<li>
<code>01_download.R</code>: Contains some code to help writing
functions that download Captchas in a real scenario. In practice, the
download functions need to be adapted because the websites are organized
in very different ways.</li>
<li>
<code>02_annotate.R</code>: Contains a <em>template</em> for manual
annotation of Captchas. Manual annotation can either be performed using
the interface created by the <a href="https://github.com/decryptr/captcha" class="external-link">captcha</a> package or
externally. The annotated files are stored in the <code>img</code>
folder.</li>
<li>
<code>03_model.R</code>: Contains a <em>template</em> for modeling,
allowing complete customization of the fitting procedure. The
<em>script</em> contains commands to load the data, specify the model,
fit the model and save the fitted model.</li>
<li>
<code>04_share.R</code>: Contains operations to create a
<em>git</em> repository of the solution and make the fitted model
available. The model can be loaded afterwards using the
<code><a href="../reference/captcha_load_model.html">captcha_load_model()</a></code> function, without the need to copy
files locally.</li>
</ul>
<div class="section level3">
<h3 id="model-r-details">
<code>03_model.R</code> details<a class="anchor" aria-label="anchor" href="#model-r-details"></a>
</h3>
<p>The first step of the <em>script</em> creates objects of type
<em>dataset</em> (object that stores the data consistently) and
<em>dataloader</em> (object that obtains samples from the dataset, which
are used as <em>minibatches</em> inside the model), using a framework
orchestrated by the <a href="https://torch.mlverse.org/docs" class="external-link">torch</a> package.</p>
<p>The <code><a href="../reference/captcha_dataset.html">captcha_dataset()</a></code> function creates the
<em>dataset</em>, taking a folder as a parameter and generates an object
with classes <code>my_captcha</code>, <code>dataset</code> and
<code>R6</code>. The function is actually a
<code>dataset_generator</code> object, created using the
<code>dataset()</code> function from the <a href="https://torch.mlverse.org/docs" class="external-link">torch</a> package.
The object is called in the same way as a usual R function, accepting
some additional parameters:</p>
<ul>
<li>
<code>transform_image=</code>: transformation function to be applied
to the image. By default, it uses the
<code><a href="../reference/captcha_transform_image.html">captcha_transform_image()</a></code> function, which reads the image
and resizes it to <code>32x192</code> dimensions. The dimension was
chosen to facilitate the implementation of convolutional layers and to
deal with the fact that usually Captchas are rectangular images.</li>
<li>
<code>transform_label=</code>: transformation function to generate
the response variable. By default, it uses the
<code><a href="../reference/captcha_transform_label.html">captcha_transform_label()</a></code> function, which receives a vector
of all possible Captcha elements and applies the <code>one_hot()</code>
operation, obtaining the matrix version of the response with zeros and
ones.</li>
<li>
<code>augmentation=</code>: operations for data augmentation. For
example, it could be a function that adds random noise to the original
image so that when one resample it, the obtained data is always
different.</li>
</ul>
<p>The <code><a href="../reference/captcha_dataset.html">captcha_dataset()</a></code> function must be used twice, once
to create the training dataset and once to create the validation
dataset. The separation of training and validation datasets must be done
manually, copying part of the classified Captchas to a new folder, using
randomization.</p>
<p>Next, the <em>dataloaders</em> are created using the
<code>dataloader()</code> function from the <a href="https://torch.mlverse.org/docs" class="external-link">torch</a>
package. In this part, the size of the <em>minibatch</em> is defined, in
addition to other possible parameters. For more details, <a href="https://torch.mlverse.org/docs/reference/dataloader.html" class="external-link">access
the function documentation at this link</a>. The <em>dataloaders</em>
must be created for both training and validation datasets.</p>
<p>The next step involves the model specification. In the modeling
<em>script</em>, the model is provided by the <code>net_captcha</code>
object of the <a href="https://github.com/decryptr/captcha" class="external-link">captcha</a> package. As in the case of
<em>dataset</em>, <code>net_captcha</code> is a special object of
<a href="https://torch.mlverse.org/docs" class="external-link">torch</a>, with classes <code>CAPTCHA-CNN</code>,
<code>nn_module</code> and <code>nn_module_generator</code>. The object
can be used as a function, generating a <code>torch</code> module,
similar to a prediction function. However, due to the way the object is
used in later steps by the <a href="https://mlverse.github.io/luz/" class="external-link">luz</a> package, the object to be
considered is the <code>nn_module_generator</code>, as stated in the
<em>script</em>.</p>
<p>To customize the model, the user must create a new module, modifying
the <code>initialize()</code> and <code>forward()</code> methods, which
can be accessed inside the <code>net_captcha$public_methods</code>
object. The first is responsible for initializing the model, containing
the description of the operations that are performed, such as
convolutions. The second is the <em>feed forward</em> function of neural
networks, which receives an image and returns an object containing the
<em>logits</em> or probabilities, in the format of the response
variable.</p>
<p>By default, the template code is as described below. The parameters
<code>input_dim=</code>, <code>output_ndigits=</code>,
<code>output_vocab_size=</code> and <code>vocab=</code> describe,
respectively, the dimensions of the image, the length of the response,
the length of the alphabet and the elements of the alphabet. The
<code>transform=</code>, <code>dropout=</code> and
<code>dense_units=</code> parameters control, respectively, the image
transformation function, the <em>dropout</em> hyperparameters and the
number of units in the dense layer. Notice that the parameters of the
convolutions are fixed, already prepared to work well with an image of
dimensions <code>32x192</code>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">initialize</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_dim</span>,</span>
<span>                      <span class="va">output_ndigits</span>,</span>
<span>                      <span class="va">output_vocab_size</span>,</span>
<span>                      <span class="va">vocab</span>,</span>
<span>                      <span class="va">transform</span>,</span>
<span>                      <span class="va">dropout</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.25</span>, <span class="fl">.25</span><span class="op">)</span>,</span>
<span>                      <span class="va">dense_units</span> <span class="op">=</span> <span class="fl">400</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># in_channels, out_channels, kernel_size, stride = 1, padding = 0</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">batchnorm0</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_batch_norm2d.html" class="external-link">nn_batch_norm2d</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">conv1</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_conv2d.html" class="external-link">nn_conv2d</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">32</span>, <span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">batchnorm1</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_batch_norm2d.html" class="external-link">nn_batch_norm2d</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">conv2</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_conv2d.html" class="external-link">nn_conv2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">64</span>, <span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">batchnorm2</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_batch_norm2d.html" class="external-link">nn_batch_norm2d</a></span><span class="op">(</span><span class="fl">64</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">conv3</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_conv2d.html" class="external-link">nn_conv2d</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">64</span>, <span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">batchnorm3</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_batch_norm2d.html" class="external-link">nn_batch_norm2d</a></span><span class="op">(</span><span class="fl">64</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">dropout1</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_dropout2d.html" class="external-link">nn_dropout2d</a></span><span class="op">(</span><span class="va">dropout</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">dropout2</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_dropout2d.html" class="external-link">nn_dropout2d</a></span><span class="op">(</span><span class="va">dropout</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">fc1</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span></span>
<span>    <span class="co"># must be the same as last convnet</span></span>
<span>    in_features <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/prod.html" class="external-link">prod</a></span><span class="op">(</span><span class="fu">calc_dim_conv</span><span class="op">(</span><span class="va">input_dim</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="fl">64</span>,</span>
<span>    out_features <span class="op">=</span> <span class="va">dense_units</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">batchnorm_dense</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_batch_norm1d.html" class="external-link">nn_batch_norm1d</a></span><span class="op">(</span><span class="va">dense_units</span><span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">fc2</span> <span class="op">&lt;-</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span></span>
<span>    in_features <span class="op">=</span> <span class="va">dense_units</span>,</span>
<span>    out_features <span class="op">=</span> <span class="va">output_vocab_size</span> <span class="op">*</span> <span class="va">output_ndigits</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">output_vocab_size</span> <span class="op">&lt;-</span> <span class="va">output_vocab_size</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">input_dim</span> <span class="op">&lt;-</span> <span class="va">input_dim</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">output_ndigits</span> <span class="op">&lt;-</span> <span class="va">output_ndigits</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">vocab</span> <span class="op">&lt;-</span> <span class="va">vocab</span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">transform</span> <span class="op">&lt;-</span> <span class="va">transform</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The <em>feed forward</em> function is described below. The function
applies the step-by-step procedure of a convolutional neural network,
with an image <code>x</code> as input and returning a logit matrix
giving the model weights for each letter of the answer. The model
returns the logits, not the probabilities, because the loss function
takes the logits as input. If the user decides to modify the
<code>forward</code> method to return probabilities, she will also need
to adapt the used loss function.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">forward</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>  <span class="va">out</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># normalize</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">batchnorm0</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># layer 1</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">conv1</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_max_pool2d.html" class="external-link">nnf_max_pool2d</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">batchnorm1</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    </span>
<span>    <span class="co"># layer 2</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">conv2</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_max_pool2d.html" class="external-link">nnf_max_pool2d</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">batchnorm2</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    </span>
<span>    <span class="co"># layer 3</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">conv3</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_max_pool2d.html" class="external-link">nnf_max_pool2d</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">batchnorm3</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    </span>
<span>    <span class="co"># dense</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/torch_flatten.html" class="external-link">torch_flatten</a></span><span class="op">(</span>start_dim <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">dropout1</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">fc1</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nnf_relu.html" class="external-link">nnf_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">batchnorm_dense</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">dropout2</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">fc2</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">out</span><span class="op">$</span><span class="fu">view</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,</span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">output_ndigits</span>,</span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">output_vocab_size</span></span>
<span>  <span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre></div>
<p>Once the architecture of the model is defined, the penultimate step
is the fitting step. It is orchestrated by the <a href="https://mlverse.github.io/luz/" class="external-link">luz</a>
package, which facilitates the creation of the optimization
<em>loop</em>. The <a href="https://mlverse.github.io/luz/" class="external-link">luz</a> package plays a role similar to
what <code>keras</code> does for <code>tensorflow</code>.</p>
<p>In the case of Captchas, the <a href="https://mlverse.github.io/luz/" class="external-link">luz</a> code to fit the model
is organized in four steps, linked by the <em>pipe</em> operator, or
<code>|&gt;</code>:</p>
<ul>
<li>
<code>setup()</code>: determines the loss function, the optimizer
and the metrics to be monitored. The loss function used in the script is
<code>nn_multilabel_soft_margin_loss()</code> from <a href="https://torch.mlverse.org/docs" class="external-link">torch</a>,
the optimizer is <code>optim_adam()</code> from <a href="https://torch.mlverse.org/docs" class="external-link">torch</a> and
the metric is <code><a href="../reference/captcha_accuracy.html">captcha_accuracy()</a></code>, developed in the
<a href="https://github.com/decryptr/captcha" class="external-link">captcha</a> package to show the accuracy considering the
complete Captcha image and not the accuracy of each letter of the image,
which would be the result if the <code>luz_metric_accuracy()</code>
function from the <a href="https://mlverse.github.io/luz/" class="external-link">luz</a> package.</li>
<li>
<code>set_hparams()</code>: informs the hyperparameters and other
model information. The parameters of this function are the same as the
<code>initialize()</code> method of the neural network created in the
previous step.</li>
<li>
<code>set_opt_hparams()</code>: informs the optimization
hyperparameters. Parameters placed in this function are passed to the
optimization function. In the script, the only used parameter is the
learning rate, fixed at <code>0.01</code>.</li>
<li>
<code>fit()</code>: initializes the optimization <em>loop</em>.
Here, it is necessary to set the training and validation
<em>dataloaders</em>, the number of epochs (by default, 100), and the
<em>callbacks</em>, which are operations to be applied at different
moments of the fitting (for example, at the end of each iteration). By
default, the <em>callbacks</em> are:
<ul>
<li>The learning rate decay parameter using a multiplicative rate. After
each iteration, the learning rate decays by a factor determined by the
function defined in <code>lr_lambda</code>, which by default is
<code>0.99</code>. That is, in each epoch, the learning rate is 1%
lower.</li>
<li>The early stopping. By default, it is set to stop if after 20 epochs
the model does not improve accuracy by 1% in the validation
dataset.</li>
<li>The <code>log</code> file. By default, the model saves the fitting
history in a <em>comma separated values</em> (CSV) file, containing the
loss and accuracy of the model in the training and validation datasets,
at the end of each epoch. The <code>log</code> file is important to
monitor the model fitting and check its performance over the
epochs.</li>
</ul>
</li>
</ul>
<p>The workflow defined by the <a href="https://mlverse.github.io/luz/" class="external-link">luz</a> package returns a
fitted model object. The model has the <code>luz_module_fitted</code>
class and can be inspected by running the object in the R console. A
example is shown below. The object contains a concise and informative
report, showing the total time, metrics obtained in training and
validation, and the architecture of the fitted model.</p>
<pre><code>A `luz_module_fitted`
── Time ────────────────────────────────────────────────
• Total time: 10m 48.1s
• Avg time per training batch: 415ms
• Avg time per validation batch 217ms

── Results ─────────────────────────────────────────────
Metrics observed in the last epoch.

ℹ Training:
loss: 0.0049
captcha acc: 0.996
ℹ Validation:
loss: 0.0356
captcha acc: 0.905

── Model ───────────────────────────────────────────────
An `nn_module` containing 628,486 parameters.

── Modules ─────────────────────────────────────────────
• batchnorm0: &lt;nn_batch_norm2d&gt; #6 parameters
• conv1: &lt;nn_conv2d&gt; #896 parameters
• batchnorm1: &lt;nn_batch_norm2d&gt; #64 parameters
• conv2: &lt;nn_conv2d&gt; #18,496 parameters
• batchnorm2: &lt;nn_batch_norm2d&gt; #128 parameters
• conv3: &lt;nn_conv2d&gt; #36,928 parameters
• batchnorm3: &lt;nn_batch_norm2d&gt; #128 parameters
• dropout1: &lt;nn_dropout&gt; #0 parameters
• dropout2: &lt;nn_dropout&gt; #0 parameters
• fc1: &lt;nn_linear&gt; #563,400 parameters
• batchnorm_dense: &lt;nn_batch_norm1d&gt; #400 parameters
• fc2: &lt;nn_linear&gt; #8,040 parameters</code></pre>
<p>Lastly, the model must be saved to a local file. This is accomplished
using the <code>luz_save()</code> function of the <a href="https://mlverse.github.io/luz/" class="external-link">luz</a>
package, saving an object with the <code>.pt</code> extension, which
will be used in <code>04_share.R</code>.</p>
</div>
<div class="section level3">
<h3 id="share-r-details">
<code>04_share.R</code> details<a class="anchor" aria-label="anchor" href="#share-r-details"></a>
</h3>
<p>The script uses the <a href="https://usethis.r-lib.org" class="external-link">usethis</a> package to organize the
repository, configuring Git (code versioning software) and GitHub
(<em>web</em> repository organization system). Furthermore, the
<em>script</em> uses the <a href="https://docs.ropensci.org/piggyback" class="external-link">piggyback</a> package to make the
fitted model available in the <em>releases</em> of the new repository.
Optionally, the user can also make the raw data with the annotated files
available in a <code>.zip</code> file, which is recommended, as it
allows other people to work with the same data and improve the
models.</p>
<p>An important detail is about the usage of heavy files in the git
repository. The <em>script</em> uses <em>releases</em> to share the
solutions because it is not good practice to upload files such as fitted
models or raw files (images) directly to the repository. This happens
because the repository can become too heavy for the git algorithm to
handle.</p>
<p>Once shared across releases in the repository, the model is readable
by anyone using the <a href="https://github.com/decryptr/captcha" class="external-link">captcha</a> package. Just run the code
below and the model will be loaded.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/captcha_load_model.html">captcha_load_model</a></span><span class="op">(</span><span class="st">"&lt;name&gt;"</span>, <span class="st">"&lt;user&gt;/&lt;repo&gt;"</span><span class="op">)</span></span></code></pre></div>
<p>With this, all the work can be shared and Captchas can be solved in a
collaborative manner by the community. Using the
<code><a href="../reference/new_captcha.html">new_captcha()</a></code> workflow, the user has the flexibility to
build custom models and the ease to share the results.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Julio Trecenti.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
